{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f24e6e-d9d5-4365-b8b0-1b8412af606e",
   "metadata": {},
   "source": [
    "In this notebook, the trained models are evaluated using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e809aa-25c9-46ee-a8dc-f02bba6a9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# DataFrame display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2593ce1-a3e9-4f00-b85c-04a7acc5fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cost_metric(y_true, y_pred):\n",
    "    # Convert predictions to probabilities\n",
    "    y_pred = tf.nn.softmax(y_pred)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    pred_class = tf.argmax(y_pred, axis=1)\n",
    "    true_class = tf.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Define cost matrix\n",
    "    cost_matrix = tf.constant([\n",
    "        [0, 7, 8, 9, 10],\n",
    "        [200, 0, 7, 8, 9],\n",
    "        [300, 200, 0, 7, 8],\n",
    "        [400, 300, 200, 0, 7],\n",
    "        [500, 400, 300, 200, 0]\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    # Calculate cost\n",
    "    costs = tf.gather_nd(cost_matrix, \n",
    "                        tf.stack([true_class, pred_class], axis=1))\n",
    "    return tf.reduce_mean(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080c2c71-ad94-4dd7-a624-67e1b27e1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPaddingGenerator(Sequence):\n",
    "    def __init__(self, groups, batch_size, label_encoder, scaler, is_training=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.groups = list(groups)\n",
    "        self.batch_size = batch_size\n",
    "        self.is_training = is_training\n",
    "        self.label_encoder = label_encoder\n",
    "        self.scaler = scaler  # Use pretrained scaler\n",
    "        self.n_samples = len(self.groups)\n",
    "        self.indexes = np.arange(self.n_samples)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.is_training:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_groups = [self.groups[i] for i in batch_indexes]\n",
    "        max_length = max(len(group[1]) for group in batch_groups)\n",
    "        \n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for vehicle_id, group in batch_groups:\n",
    "            if self.is_training:\n",
    "                time_series = group.sort_values('time_step').iloc[:, 2:-3].values\n",
    "                label = group['class_labels'].iloc[0]\n",
    "            else:\n",
    "                time_series = group.sort_values('time_step').iloc[:, 2:].values\n",
    "                label = test_labels.loc[test_labels['vehicle_id'] == vehicle_id, 'class_label'].values[0]\n",
    "            \n",
    "            time_series = self.scaler.transform(time_series)\n",
    "            padded_series = pad_sequences([time_series], maxlen=max_length, padding='post', dtype='float32')[0]\n",
    "            \n",
    "            X_batch.append(padded_series)\n",
    "            encoded_label = tf.keras.utils.to_categorical(\n",
    "                self.label_encoder.transform([label])[0], \n",
    "                num_classes=5\n",
    "            )\n",
    "            y_batch.append(encoded_label)\n",
    "        \n",
    "        return np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c559ff81-10b6-4443-86ba-836453a59229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, pred_labels, label_encoder, model_name):\n",
    "    sns.heatmap(\n",
    "        confusion_matrix(true_labels, pred_labels),\n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875db3cc-c91e-47bb-befd-4eb1ad25c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(true_labels, predicted_labels):\n",
    "    cost_matrix = np.array([\n",
    "        [0, 7, 8, 9, 10],\n",
    "        [200, 0, 7, 8, 9],\n",
    "        [300, 200, 0, 7, 8],\n",
    "        [400, 300, 200, 0, 7],\n",
    "        [500, 400, 300, 200, 0]\n",
    "    ])\n",
    "    total_cost = 0\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        total_cost += cost_matrix[true, pred]\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e356ad-8b2e-4adf-a102-1346d9d9450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_operational = pd.read_csv('selected_and_filled_test_operational_readouts.csv')\n",
    "test_labels = pd.read_csv('test_labels.csv')\n",
    "\n",
    "model_dir = \"trained_model_bilstm_attention_deneme\"\n",
    "\n",
    "# Load label encoder and scaler\n",
    "le = joblib.load(os.path.join(model_dir, 'label_encoder.joblib'))\n",
    "scaler = joblib.load(os.path.join(model_dir, 'standard_scaler.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27d1d78-86e5-47f1-9747-5ee886c4cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test generator with the loaded scaler\n",
    "batch_size = 64\n",
    "test_generator = DynamicPaddingGenerator(\n",
    "    test_operational.groupby('vehicle_id'),\n",
    "    batch_size,\n",
    "    le,\n",
    "    scaler,  \n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Evaluate all models in directory\n",
    "model_files = [f for f in os.listdir(model_dir) if f.endswith('.keras')]\n",
    "\n",
    "# Create directory for confusion matrix plots\n",
    "plot_dir = os.path.join(model_dir, 'evaluation_plots')\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c122aa29-f87c-402e-9ebc-1b4968ff1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention Layer for model loading\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, attention_units=128, return_attention=False, **kwargs):\n",
    "        self.attention_units = attention_units\n",
    "        self.return_attention = return_attention\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.input_dim = input_shape[2]\n",
    "        \n",
    "        self.query_dense = Dense(self.attention_units)\n",
    "        self.key_dense = Dense(self.attention_units)\n",
    "        self.value_dense = Dense(self.input_dim)  \n",
    "        \n",
    "        self.context_dense = Dense(self.input_dim)\n",
    "        \n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query = self.query_dense(inputs)  \n",
    "        key = self.key_dense(inputs)      \n",
    "        value = self.value_dense(inputs)  \n",
    "        \n",
    "        score = tf.matmul(query, key, transpose_b=True)  \n",
    "        score = score / tf.math.sqrt(tf.cast(self.attention_units, tf.float32))\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)  \n",
    "        \n",
    "        context = tf.matmul(attention_weights, value) \n",
    "        \n",
    "        output = self.context_dense(context)  \n",
    "        \n",
    "        if self.return_attention:\n",
    "            return output, attention_weights\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[1], self.input_dim), \n",
    "                    (input_shape[0], input_shape[1], input_shape[1])]\n",
    "        return (input_shape[0], input_shape[1], self.input_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SelfAttention, self).get_config()\n",
    "        config.update({\n",
    "            'attention_units': self.attention_units,\n",
    "            'return_attention': self.return_attention\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098c6130-ae7d-432f-a75e-d85d349257eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bilstm_attention_model_epoch_01.keras...\n",
      "Evaluating bilstm_attention_model_epoch_02.keras...\n",
      "Evaluating bilstm_attention_model_epoch_03.keras...\n",
      "Evaluating bilstm_attention_model_epoch_04.keras...\n",
      "Evaluating bilstm_attention_model_epoch_05.keras...\n",
      "Evaluating bilstm_attention_model_epoch_06.keras...\n",
      "Evaluating bilstm_attention_model_epoch_07.keras...\n",
      "Evaluating bilstm_attention_model_epoch_08.keras...\n",
      "Evaluating bilstm_attention_model_epoch_09.keras...\n",
      "Evaluating bilstm_attention_model_epoch_10.keras...\n",
      "Evaluating bilstm_attention_model_epoch_11.keras...\n",
      "Evaluating bilstm_attention_model_epoch_12.keras...\n",
      "Evaluating bilstm_attention_model_epoch_13.keras...\n",
      "Evaluating bilstm_attention_model_epoch_14.keras...\n",
      "Evaluating bilstm_attention_model_epoch_15.keras...\n",
      "Evaluating bilstm_attention_model_epoch_16.keras...\n",
      "Evaluating bilstm_attention_model_epoch_17.keras...\n",
      "Evaluating bilstm_attention_model_epoch_18.keras...\n",
      "Evaluating bilstm_attention_model_epoch_19.keras...\n",
      "Evaluating bilstm_attention_model_epoch_20.keras...\n",
      "Evaluating bilstm_attention_model_epoch_57.keras...\n"
     ]
    }
   ],
   "source": [
    "for model_file in model_files:\n",
    "    try:\n",
    "        print(f\"Evaluating {model_file}...\")\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        model = load_model(model_path, custom_objects={'SelfAttention': SelfAttention(), 'custom_cost_metric': custom_cost_metric})\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        \n",
    "        for i in range(len(test_generator)):\n",
    "            X_test, y_test = test_generator[i]\n",
    "            batch_predictions = model.predict(X_test, verbose=0)\n",
    "            batch_predictions = tf.nn.softmax(batch_predictions)  # Apply softmax to logits\n",
    "            all_predictions.extend(np.argmax(batch_predictions, axis=1))\n",
    "            all_true_labels.extend(np.argmax(y_test, axis=1))\n",
    "        \n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_true_labels = np.array(all_true_labels)\n",
    "        \n",
    "        accuracy = np.mean(all_predictions == all_true_labels)\n",
    "        total_cost = calculate_cost(all_true_labels, all_predictions)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plot_confusion_matrix(all_true_labels, all_predictions, le, model_file)\n",
    "        plt.savefig(os.path.join(plot_dir, f'confusion_matrix_{model_file}.png'))\n",
    "        plt.close() \n",
    "        \n",
    "        results.append({\n",
    "            'model_name': model_file,\n",
    "            'accuracy': accuracy,\n",
    "            'total_cost': total_cost\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85967f05-865f-4c5a-b09c-fe0494068950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "                               model_name  accuracy  total_cost  epoch\n",
      "0   bilstm_attention_model_epoch_01.keras  0.013479       62785    1.0\n",
      "1   bilstm_attention_model_epoch_02.keras  0.224975       46137    2.0\n",
      "2   bilstm_attention_model_epoch_03.keras  0.268583       45552    3.0\n",
      "3   bilstm_attention_model_epoch_04.keras  0.314371       45332    4.0\n",
      "4   bilstm_attention_model_epoch_05.keras  0.265213       46120    5.0\n",
      "5   bilstm_attention_model_epoch_06.keras  0.408722       42951    6.0\n",
      "6   bilstm_attention_model_epoch_07.keras  0.234291       44592    7.0\n",
      "7   bilstm_attention_model_epoch_08.keras  0.287611       46807    8.0\n",
      "8   bilstm_attention_model_epoch_09.keras  0.188107       46021    9.0\n",
      "9   bilstm_attention_model_epoch_10.keras  0.260258       44760   10.0\n",
      "10  bilstm_attention_model_epoch_11.keras  0.181368       44295   11.0\n",
      "11  bilstm_attention_model_epoch_12.keras  0.293558       45993   12.0\n",
      "12  bilstm_attention_model_epoch_13.keras  0.188305       43900   13.0\n",
      "13  bilstm_attention_model_epoch_14.keras  0.280476       44288   14.0\n",
      "14  bilstm_attention_model_epoch_15.keras  0.229534       45020   15.0\n",
      "15  bilstm_attention_model_epoch_16.keras  0.246581       47328   16.0\n",
      "16  bilstm_attention_model_epoch_17.keras  0.329039       45167   17.0\n",
      "17  bilstm_attention_model_epoch_18.keras  0.263429       48258   18.0\n",
      "18  bilstm_attention_model_epoch_19.keras  0.323092       44941   19.0\n",
      "19  bilstm_attention_model_epoch_20.keras  0.263826       48934   20.0\n",
      "20  bilstm_attention_model_epoch_57.keras  0.404163       47126   57.0\n"
     ]
    }
   ],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['epoch'] = results_df['model_name'].str.extract(r'epoch_(\\d+)').astype(float)\n",
    "results_df = results_df.sort_values('epoch')\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464f6546-3073-4f0f-8710-140e521488eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Models by Accuracy:\n",
      "                               model_name  accuracy  total_cost\n",
      "5   bilstm_attention_model_epoch_06.keras  0.408722       42951\n",
      "20  bilstm_attention_model_epoch_57.keras  0.404163       47126\n",
      "16  bilstm_attention_model_epoch_17.keras  0.329039       45167\n",
      "18  bilstm_attention_model_epoch_19.keras  0.323092       44941\n",
      "3   bilstm_attention_model_epoch_04.keras  0.314371       45332\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Models by Accuracy:\")\n",
    "print(results_df.nlargest(5, 'accuracy')[['model_name', 'accuracy', 'total_cost']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad6f461-f333-427e-901c-2f88b76131c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Models by Total Cost (lowest):\n",
      "                               model_name  accuracy  total_cost\n",
      "5   bilstm_attention_model_epoch_06.keras  0.408722       42951\n",
      "12  bilstm_attention_model_epoch_13.keras  0.188305       43900\n",
      "13  bilstm_attention_model_epoch_14.keras  0.280476       44288\n",
      "10  bilstm_attention_model_epoch_11.keras  0.181368       44295\n",
      "6   bilstm_attention_model_epoch_07.keras  0.234291       44592\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Models by Total Cost (lowest):\")\n",
    "print(results_df.nsmallest(5, 'total_cost')[['model_name', 'accuracy', 'total_cost']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d753abfd-5673-4640-9449-076d16f62400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(results_df['epoch'], results_df['accuracy'])\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(results_df['epoch'], results_df['total_cost'])\n",
    "plt.title('Total Cost vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Cost')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_dir, 'metrics_over_epochs.png'))\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ebbc69-cd79-49b3-af86-958b257aab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv(os.path.join(model_dir, 'model_evaluation_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ce842-865f-428c-81aa-d114e6d745f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
