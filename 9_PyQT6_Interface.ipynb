{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb90bcb4-1f2b-4b1e-bee9-f77acd291d73",
   "metadata": {},
   "source": [
    "This notebook includes a PyQt6 interface that generates visual explanation images of the modelâ€™s predictions and compiles them into an HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf7f2b5-6ca7-49c6-bf4a-be2a77116e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt6.QtWidgets import (\n",
    "    QApplication, QMainWindow, QLabel, QPushButton, QFileDialog, \n",
    "    QVBoxLayout, QHBoxLayout, QWidget, QProgressBar, QTextEdit,\n",
    "    QTableView, QSplitter, QTabWidget, QComboBox, QFrame\n",
    ")\n",
    "from PyQt6.QtCore import Qt, QThread, pyqtSignal, QSize\n",
    "from PyQt6.QtGui import QStandardItemModel, QStandardItem, QPalette, QColor\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Input, LSTM, Bidirectional, Dropout, concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from lime import lime_tabular\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a982f40-aeaf-43f9-9f7a-9ff9c6830e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(Layer):\n",
    "    def __init__(self, attention_units=128, return_attention=False, **kwargs):\n",
    "        self.attention_units = attention_units\n",
    "        self.return_attention = return_attention\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.input_dim = input_shape[2]\n",
    "\n",
    "        self.query_dense = Dense(self.attention_units)\n",
    "        self.key_dense = Dense(self.attention_units)\n",
    "        self.value_dense = Dense(self.input_dim)  \n",
    "        \n",
    "        self.context_dense = Dense(self.input_dim)\n",
    "        \n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query = self.query_dense(inputs)  \n",
    "        key = self.key_dense(inputs)     \n",
    "        value = self.value_dense(inputs)  \n",
    "        \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        score = score / tf.math.sqrt(tf.cast(self.attention_units, tf.float32))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)  \n",
    "        \n",
    "        context = tf.matmul(attention_weights, value)  \n",
    "        \n",
    "        output = self.context_dense(context)  \n",
    "        \n",
    "        if self.return_attention:\n",
    "            return output, attention_weights\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[1], self.input_dim), \n",
    "                    (input_shape[0], input_shape[1], input_shape[1])]\n",
    "        return (input_shape[0], input_shape[1], self.input_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SelfAttention, self).get_config()\n",
    "        config.update({\n",
    "            'attention_units': self.attention_units,\n",
    "            'return_attention': self.return_attention\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37788fd0-3b43-4eaa-89d6-defd8f886c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTableModel(QStandardItemModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def load_data(self, data):\n",
    "        self.clear()\n",
    "        self.setHorizontalHeaderLabels(data.columns)\n",
    "        \n",
    "        # Only show first 1000 rows for performance\n",
    "        display_data = data.head(1000)\n",
    "        for row in range(len(display_data)):\n",
    "            items = [QStandardItem(str(display_data.iloc[row, col])) for col in range(len(display_data.columns))]\n",
    "            self.appendRow(items)\n",
    "\n",
    "class StyledProgressBar(QProgressBar):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QProgressBar {\n",
    "                border: 2px solid grey;\n",
    "                border-radius: 5px;\n",
    "                text-align: center;\n",
    "            }\n",
    "            QProgressBar::chunk {\n",
    "                background-color: #4CAF50;\n",
    "                width: 10px;\n",
    "                margin: 0.5px;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class StyledButton(QPushButton):\n",
    "    def __init__(self, text):\n",
    "        super().__init__(text)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background-color: #4CAF50;\n",
    "                color: white;\n",
    "                border: none;\n",
    "                padding: 8px 16px;\n",
    "                border-radius: 4px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #45a049;\n",
    "            }\n",
    "            QPushButton:disabled {\n",
    "                background-color: #cccccc;\n",
    "            }\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872edb92-bd12-4a70-8460-b6434c7b0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessingPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop=None):\n",
    "        self.columns_to_drop = columns_to_drop if columns_to_drop is not None else [\n",
    "            '427_0', '167_5', '272_0', '272_1', '272_4', '835_0', '291_1', '291_2', \n",
    "            '291_6', '291_7', '291_8', '291_9', '291_10', '158_1', '158_2', '158_3', \n",
    "            '158_4', '158_5', '158_6', '158_7', '158_8', '459_3', '459_4', '459_5', \n",
    "            '459_6', '459_7', '459_8', '459_9', '459_10', '459_11', '459_12', '397_1', \n",
    "            '397_2', '397_13', '397_14', '397_16', '397_19', '397_20', '397_21', \n",
    "            '397_26', '397_28', '397_29', '397_32', '397_33'\n",
    "        ]\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, data):\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Drop specified columns if they exist\n",
    "        existing_columns = [col for col in self.columns_to_drop if col in df.columns]\n",
    "        df = df.drop(columns=existing_columns)\n",
    "        \n",
    "        df = df.groupby('vehicle_id').apply(self._handle_missing_values).reset_index(drop=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _handle_missing_values(self, group):\n",
    "        # Forward fill\n",
    "        group = group.fillna(method='ffill')\n",
    "        # Backward fill remaining missing values\n",
    "        group = group.fillna(method='bfill')\n",
    "        # Fill any remaining missing values with 0\n",
    "        group = group.fillna(0)\n",
    "        return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affd0ac3-b564-424d-bf39-242e3a6d346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIMEReportThread(QThread):\n",
    "    progress = pyqtSignal(int)\n",
    "    status = pyqtSignal(str)\n",
    "    finished = pyqtSignal(str)\n",
    "    error = pyqtSignal(str)\n",
    "\n",
    "    def __init__(self, data_path, model_path, num_instances):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.model_path = model_path\n",
    "        self.requested_instances = num_instances\n",
    "        # Try to load the label encoder from the same directory as the model\n",
    "        self.label_encoder_path = os.path.join(os.path.dirname(model_path), 'label_encoder.joblib')\n",
    "        # Path to the saved scaler\n",
    "        self.scaler_path = os.path.join(os.path.dirname(model_path), 'standard_scaler.joblib')\n",
    "        self.pipeline = DataPreprocessingPipeline()\n",
    "\n",
    "    def weighted_loss(self, y_true, y_pred):\n",
    "        cost_matrix = tf.constant([\n",
    "            [0, 7, 8, 9, 10],\n",
    "            [200, 0, 7, 8, 9],\n",
    "            [300, 200, 0, 7, 8],\n",
    "            [400, 300, 200, 0, 7],\n",
    "            [500, 400, 300, 200, 0]\n",
    "        ], dtype=tf.float32)\n",
    "        \n",
    "        y_true_onehot = tf.one_hot(tf.cast(tf.squeeze(y_true), tf.int32), depth=5)\n",
    "        cost_weighted_pred = tf.matmul(y_pred, tf.transpose(cost_matrix))\n",
    "        weighted_output = tf.reduce_sum(y_true_onehot * cost_weighted_pred, axis=1)\n",
    "        base_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        return tf.reduce_mean(base_loss * weighted_output)\n",
    "\n",
    "    def custom_cost_metric(self, y_true, y_pred):\n",
    "        # Convert predictions to probabilities\n",
    "        y_pred = tf.nn.softmax(y_pred)\n",
    "        \n",
    "        # Get the predicted class\n",
    "        pred_class = tf.argmax(y_pred, axis=1)\n",
    "        true_class = tf.argmax(y_true, axis=1)\n",
    "        \n",
    "        # Define cost matrix\n",
    "        cost_matrix = tf.constant([\n",
    "            [0, 7, 8, 9, 10],\n",
    "            [200, 0, 7, 8, 9],\n",
    "            [300, 200, 0, 7, 8],\n",
    "            [400, 300, 200, 0, 7],\n",
    "            [500, 400, 300, 200, 0]\n",
    "        ], dtype=tf.float32)\n",
    "        \n",
    "        # Calculate cost\n",
    "        costs = tf.gather_nd(cost_matrix, \n",
    "                            tf.stack([true_class, pred_class], axis=1))\n",
    "        return tf.reduce_mean(costs)\n",
    "\n",
    "    def preprocess_test_data(self, data):\n",
    "        X, vehicle_ids = [], []\n",
    "        grouped = data.groupby('vehicle_id')\n",
    "        \n",
    "        # Load the pre-trained scaler\n",
    "        try:\n",
    "            scaler = joblib.load(self.scaler_path)\n",
    "            self.status.emit(\"Pre-trained scaler loaded successfully\")\n",
    "        except Exception as e:\n",
    "            self.error.emit(f\"Error loading scaler: {str(e)}\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Find max length in this batch\n",
    "        max_length = max(len(group) for _, group in grouped)\n",
    "        \n",
    "        for vehicle_id, group in grouped:\n",
    "            time_series = group.sort_values('time_step').iloc[:, 2:].values\n",
    "            time_series = scaler.transform(time_series)\n",
    "            X.append(time_series)\n",
    "            vehicle_ids.append(vehicle_id)\n",
    "        \n",
    "        # Pad sequences to max length in batch\n",
    "        X_padded = pad_sequences(X, maxlen=max_length, padding='post', dtype='float32')\n",
    "        return X_padded, vehicle_ids, max_length\n",
    "\n",
    "    def create_attention_model(self, original_model):\n",
    "        \"\"\"Create a model that returns attention weights\"\"\"\n",
    "        # Find the attention layer in the model\n",
    "        attention_layer = None\n",
    "        attention_layer_index = -1\n",
    "        \n",
    "        for i, layer in enumerate(original_model.layers):\n",
    "            if isinstance(layer, SelfAttention):\n",
    "                attention_layer = layer\n",
    "                attention_layer_index = i\n",
    "                break\n",
    "        \n",
    "        if attention_layer is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Create new attention layer that returns weights\n",
    "        new_attention = SelfAttention(\n",
    "            attention_units=attention_layer.attention_units,\n",
    "            return_attention=True\n",
    "        )\n",
    "        \n",
    "        # Safer approach: Get the input to the attention layer\n",
    "        if attention_layer_index > 0:\n",
    "            # Get the output of the layer before attention\n",
    "            pre_attention_model = Model(\n",
    "                inputs=original_model.input,\n",
    "                outputs=original_model.layers[attention_layer_index - 1].output\n",
    "            )\n",
    "            \n",
    "            # Create a simple model just for attention weights\n",
    "            attention_input = Input(shape=pre_attention_model.output_shape[1:])\n",
    "            attention_output, attention_weights = new_attention(attention_input)\n",
    "            simple_attention_model = Model(inputs=attention_input, outputs=[attention_output, attention_weights])\n",
    "            \n",
    "            # Copy weights to new attention layer\n",
    "            new_attention.set_weights(attention_layer.get_weights())\n",
    "            \n",
    "            return (pre_attention_model, simple_attention_model), True\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "    def visualize_attention(self, instance_idx, X_test, predictions, vehicle_ids, label_encoder, results_dir, model):\n",
    "        \"\"\"Generate attention visualization for a single instance\"\"\"\n",
    "        # Create attention model\n",
    "        models, has_attention = self.create_attention_model(model)\n",
    "        \n",
    "        if not has_attention:\n",
    "            self.status.emit(\"Model does not have attention layer, skipping attention visualization\")\n",
    "            return None\n",
    "        \n",
    "        pre_attention_model, attention_model = models\n",
    "        \n",
    "        # Get attention weights for this instance\n",
    "        instance_data = X_test[instance_idx:instance_idx+1]\n",
    "        \n",
    "        # First, get the pre-attention features\n",
    "        pre_attention_features = pre_attention_model.predict(instance_data, verbose=0)\n",
    "        \n",
    "        # Then get attention weights\n",
    "        _, attention_weights = attention_model.predict(pre_attention_features, verbose=0)\n",
    "        \n",
    "        # Get predictions\n",
    "        probs = tf.nn.softmax(predictions[instance_idx]).numpy()\n",
    "        predicted_class = np.argmax(probs)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # First subplot: Attention Heatmap\n",
    "        plt.subplot(2, 1, 1)\n",
    "        \n",
    "        # Find non-zero time steps (remove padding)\n",
    "        non_zero_steps = np.any(X_test[instance_idx] != 0, axis=1)\n",
    "        actual_length = np.sum(non_zero_steps)\n",
    "        \n",
    "        # Get relevant part of attention weights\n",
    "        relevant_attention = attention_weights[0][:actual_length, :actual_length]\n",
    "        \n",
    "        # Show heatmap\n",
    "        sns.heatmap(relevant_attention, cmap='viridis')\n",
    "        plt.title(f'Attention Weights for Vehicle {vehicle_ids[instance_idx]}')\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Time Steps')\n",
    "        \n",
    "        # Second subplot: Prediction probabilities\n",
    "        plt.subplot(2, 1, 2)\n",
    "        class_names = label_encoder.classes_\n",
    "        \n",
    "        # Prediction probabilities\n",
    "        bars = plt.bar(class_names, probs)\n",
    "        \n",
    "        # Highlight predicted class\n",
    "        for j, bar in enumerate(bars):\n",
    "            if j == predicted_class:\n",
    "                bar.set_color('green')\n",
    "        \n",
    "        plt.axhline(y=0.2, color='gray', linestyle='--')  # Reference line\n",
    "        plt.title(f'Class Predictions: Predicted={class_names[predicted_class]}')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height*100:.1f}%',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        attention_filename = f\"attention_visualization_vehicle_{vehicle_ids[instance_idx]}.png\"\n",
    "        plt.savefig(os.path.join(results_dir, attention_filename))\n",
    "        plt.close()\n",
    "        \n",
    "        return attention_filename\n",
    "\n",
    "    def create_feature_importance_plots_for_vehicle(self, instance_idx, X_test, vehicle_ids, label_encoder, results_dir, model):\n",
    "        \"\"\"Generate feature importance plots for a specific vehicle\"\"\"\n",
    "        # Create attention model\n",
    "        models, has_attention = self.create_attention_model(model)\n",
    "        \n",
    "        if not has_attention:\n",
    "            self.status.emit(\"Model does not have attention layer, skipping feature importance plots\")\n",
    "            return None, None\n",
    "        \n",
    "        pre_attention_model, attention_model = models\n",
    "        \n",
    "        # Get attention weights for this specific instance\n",
    "        instance_data = X_test[instance_idx:instance_idx+1]\n",
    "        pre_features = pre_attention_model.predict(instance_data)\n",
    "        _, attention_weights = attention_model.predict(pre_features)\n",
    "        \n",
    "        # Find actual length (non-padding)\n",
    "        actual_length = np.sum(np.any(X_test[instance_idx] != 0, axis=1))\n",
    "        \n",
    "        # Attention matrix for this example\n",
    "        att_matrix = attention_weights[0][:actual_length, :actual_length]\n",
    "        \n",
    "        # Time step importance - use column means instead of row sums\n",
    "        # This gives us how much each time step is attended to\n",
    "        step_importance = np.mean(att_matrix, axis=0)\n",
    "        \n",
    "        # Alternative calculation: max attention per time step\n",
    "        max_attention = np.max(att_matrix, axis=0)\n",
    "        \n",
    "        # Combine both metrics for more robust importance scores\n",
    "        combined_importance = (step_importance + max_attention) / 2\n",
    "        \n",
    "        # Add variance to capture attention spread\n",
    "        attention_variance = np.var(att_matrix, axis=0)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Plot 1: Combined importance\n",
    "        ax1.plot(range(len(combined_importance)), combined_importance, marker='o', linewidth=2, markersize=8, label='Combined')\n",
    "        ax1.plot(range(len(step_importance)), step_importance, marker='s', linewidth=1.5, markersize=6, alpha=0.7, label='Mean Attention')\n",
    "        ax1.plot(range(len(max_attention)), max_attention, marker='^', linewidth=1.5, markersize=6, alpha=0.7, label='Max Attention')\n",
    "        \n",
    "        ax1.set_title(f'Feature Importance Across Time Steps - Vehicle {vehicle_ids[instance_idx]}', fontsize=16)\n",
    "        ax1.set_xlabel('Time Steps', fontsize=14)\n",
    "        ax1.set_ylabel('Importance Score', fontsize=14)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Add importance values as text on the plot for top values\n",
    "        top_indices = np.argsort(combined_importance)[-10:]  # Top 10 time steps\n",
    "        for idx in top_indices:\n",
    "            if idx < len(combined_importance):\n",
    "                ax1.text(idx, combined_importance[idx] + 0.01, f'{combined_importance[idx]:.3f}', \n",
    "                        ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "        \n",
    "        # Plot 2: Attention variance (shows which time steps have more varied attention)\n",
    "        ax2.bar(range(len(attention_variance)), attention_variance, alpha=0.7, color='darkblue')\n",
    "        ax2.set_title('Attention Variance per Time Step', fontsize=14)\n",
    "        ax2.set_xlabel('Time Steps', fontsize=14)\n",
    "        ax2.set_ylabel('Variance', fontsize=14)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        feature_importance_filename = f'feature_importance_vehicle_{vehicle_ids[instance_idx]}.png'\n",
    "        plt.savefig(os.path.join(results_dir, feature_importance_filename))\n",
    "        plt.close()\n",
    "        \n",
    "        return feature_importance_filename, None\n",
    "\n",
    "    def create_lime_explanation(self, instance_idx, explanation, time_series_length, X_test, predictions, results_dir, vehicle_ids, feature_names):\n",
    "        weights_df = pd.DataFrame(explanation.as_list(), columns=[\"Feature\", \"Weight\"])\n",
    "        weights_df['base_feature'] = weights_df['Feature'].apply(lambda x: '_'.join(x.split('_')[1:3]) if len(x.split('_')) >= 4 else x)\n",
    "        weights_df['abs_weight'] = weights_df['Weight'].abs()\n",
    "        top_20_weights = weights_df.nlargest(20, 'abs_weight')\n",
    "        weights_df = weights_df.drop('abs_weight', axis=1)\n",
    "        top_20_weights = top_20_weights.drop('abs_weight', axis=1)\n",
    "        unique_base_features = sorted(top_20_weights['base_feature'].unique())\n",
    "        time_series_data = X_test[instance_idx]\n",
    "\n",
    "        # Generate plots\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        top_20_sorted = top_20_weights.sort_values('Weight', ascending=True)\n",
    "        colors = ['red' if w < 0 else 'green' for w in top_20_sorted['Weight']]\n",
    "        bars = plt.barh(range(len(top_20_sorted)), top_20_sorted['Weight'], color=colors)\n",
    "        plt.yticks(range(len(top_20_sorted)), top_20_sorted['Feature'], fontsize=10)\n",
    "        plt.xlabel(\"Impact on Prediction (Weight)\", fontsize=14)\n",
    "        plt.title(f\"Top 20 Most Influential Features for Instance {vehicle_ids[instance_idx]}\", fontsize=18)\n",
    "        plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{width:.3f}',\n",
    "                    ha='left' if width >= 0 else 'right',\n",
    "                    va='center',\n",
    "                    fontsize=10)\n",
    "        \n",
    "        feature_plot_filename = f\"feature_importance_{vehicle_ids[instance_idx]}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, feature_plot_filename))\n",
    "        plt.close()\n",
    "\n",
    "        # Create time series visualizations\n",
    "        feature_indices = {}\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            base_feature = feature\n",
    "            if '_' in feature:\n",
    "                parts = feature.split('_')\n",
    "                if len(parts) >= 2:\n",
    "                    base_feature = f\"{parts[0]}_{parts[1]}\"\n",
    "            feature_indices[base_feature] = i\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for base_feature in unique_base_features:\n",
    "            if base_feature in feature_indices:\n",
    "                feature_idx = feature_indices[base_feature]\n",
    "                plt.plot(range(time_series_length), \n",
    "                        time_series_data[:time_series_length, feature_idx], \n",
    "                        label=f'Feature {base_feature}')\n",
    "        \n",
    "        plt.title('Time Series of Selected Features (From Top 20)', fontsize=14)\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Normalized Value')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        timeseries_plot_filename = f\"timeseries_{vehicle_ids[instance_idx]}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, timeseries_plot_filename), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Feature correlation plot\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        selected_data = {}\n",
    "        for base_feature in unique_base_features:\n",
    "            if base_feature in feature_indices:\n",
    "                feature_idx = feature_indices[base_feature]\n",
    "                selected_data[base_feature] = time_series_data[:time_series_length, feature_idx]\n",
    "        \n",
    "        if selected_data:\n",
    "            correlation_matrix = pd.DataFrame(selected_data).corr()\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "            plt.title('Feature Correlation Heatmap (From Top 20 Features)', fontsize=14)\n",
    "        correlation_plot_filename = f\"correlation_{vehicle_ids[instance_idx]}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, correlation_plot_filename))\n",
    "        plt.close()\n",
    "\n",
    "        # Feature distribution plot\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        for base_feature in unique_base_features:\n",
    "            if base_feature in feature_indices:\n",
    "                feature_idx = feature_indices[base_feature]\n",
    "                sns.kdeplot(time_series_data[:time_series_length, feature_idx], \n",
    "                           label=f'Feature {base_feature}')\n",
    "        \n",
    "        plt.title('Feature Value Distributions (From Top 20 Features)', fontsize=14)\n",
    "        plt.xlabel('Normalized Value')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        distribution_plot_filename = f\"distribution_{vehicle_ids[instance_idx]}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, distribution_plot_filename), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        return {\n",
    "            'feature': feature_plot_filename,\n",
    "            'timeseries': timeseries_plot_filename,\n",
    "            'correlation': correlation_plot_filename,\n",
    "            'distribution': distribution_plot_filename\n",
    "        }, top_20_weights\n",
    "\n",
    "    def create_detailed_report(self, instance_idx, explanation, predictions, feature_names, label_encoder, plot_files, weights_df, results_dir, attention_plot, feature_importance_plots):\n",
    "        predicted_class = np.argmax(predictions[instance_idx])\n",
    "        messages = {\n",
    "            0: \"The truck is not expected to fail within the next 48 hours.\",\n",
    "            1: \"The truck is expected to fail within 24-48 hours.\",\n",
    "            2: \"The truck is expected to fail within 12-24 hours.\",\n",
    "            3: \"The truck is expected to fail within 6-12 hours.\",\n",
    "            4: \"The truck is expected to fail within 0-6 hours.\"\n",
    "        }\n",
    "        prediction_message = messages[predicted_class]\n",
    "        \n",
    "        # Check if visualizations directory exists and get visualization images\n",
    "        visualizations_dir = os.path.join(os.getcwd(), \"visualizations\")\n",
    "        viz_images = []\n",
    "        viz_descriptions = {\n",
    "            \"permutation_feature_importance_bar.png\": {\n",
    "                \"title\": \"Permutation Feature Importance (Bar Chart)\",\n",
    "                \"description\": \"This bar chart shows the top 20 most important features determined by GPU-accelerated permutation. The importance score indicates how much the model's performance degrades when that feature's values are randomly shuffled. Higher scores indicate more critical features for the model's predictions.\"\n",
    "            },\n",
    "            \"permutation_importance_heatmap.png\": {\n",
    "                \"title\": \"Feature Importance Heatmap by Class\",\n",
    "                \"description\": \"This heatmap displays feature importance scores across all prediction classes (0-4). The color intensity represents the importance level for each feature-class combination. Darker regions indicate higher importance, helping identify which features are most relevant for specific failure time windows.\"\n",
    "            },\n",
    "            \"class_specific_feature_importance.png\": {\n",
    "                \"title\": \"Class-Specific Feature Importance Analysis\",\n",
    "                \"description\": \"These subplots show the top 15 features for each prediction class (0-4 representing different failure time windows). Each class has its own importance ranking, revealing which features are most predictive for specific failure scenarios. This analysis helps understand the model's decision-making process for different risk levels.\"\n",
    "            },\n",
    "            \"feature_importance_variance.png\": {\n",
    "                \"title\": \"Feature Importance Variance Analysis\",\n",
    "                \"description\": \"This chart shows features with the highest variance in importance across different classes. High variance indicates that a feature's importance changes significantly depending on the prediction class, suggesting these features are particularly discriminative for distinguishing between different failure time windows.\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if os.path.exists(visualizations_dir):\n",
    "            for image_name in [\"permutation_feature_importance_bar.png\", \"permutation_importance_heatmap.png\", \n",
    "                              \"class_specific_feature_importance.png\", \"feature_importance_variance.png\"]:\n",
    "                image_path = os.path.join(visualizations_dir, image_name)\n",
    "                if os.path.exists(image_path):\n",
    "                    # Use relative path for HTML - The visualizations folder is two levels above the batch directory\n",
    "                    relative_path = f\"../../../visualizations/{image_name}\"\n",
    "                    viz_images.append({\n",
    "                        \"path\": relative_path,\n",
    "                        \"title\": viz_descriptions[image_name][\"title\"],\n",
    "                        \"description\": viz_descriptions[image_name][\"description\"]\n",
    "                    })\n",
    "        \n",
    "        report_filename = f\"explanation_report_instance_{instance_idx}.html\"\n",
    "        report_path = os.path.join(results_dir, report_filename)\n",
    "\n",
    "        html_content = f\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>LIME Explanation Report - Instance {instance_idx}</title>\n",
    "            <style>\n",
    "                body {{ \n",
    "                    font-family: Arial, sans-serif; \n",
    "                    margin: 20px; \n",
    "                    text-align: center; \n",
    "                    background-color: #f5f5f5;\n",
    "                }}\n",
    "                .container {{ \n",
    "                    max-width: 1200px; \n",
    "                    margin: auto; \n",
    "                    background-color: white;\n",
    "                    padding: 20px;\n",
    "                    border-radius: 10px;\n",
    "                    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "                }}\n",
    "                .section {{ \n",
    "                    margin-bottom: 40px; \n",
    "                    display: none;\n",
    "                }}\n",
    "                .section.active {{\n",
    "                    display: block;\n",
    "                }}\n",
    "                .analysis-subsection {{\n",
    "                    margin-bottom: 30px;\n",
    "                    padding: 20px;\n",
    "                    border: 1px solid #ddd;\n",
    "                    border-radius: 8px;\n",
    "                    background-color: #fafafa;\n",
    "                }}\n",
    "                .feature-table {{ \n",
    "                    width: 100%; \n",
    "                    border-collapse: collapse; \n",
    "                    margin: auto; \n",
    "                }}\n",
    "                .feature-table th, .feature-table td {{ \n",
    "                    border: 1px solid #ddd; \n",
    "                    padding: 8px; \n",
    "                    text-align: center; \n",
    "                }}\n",
    "                .feature-table tr:nth-child(even) {{ \n",
    "                    background-color: #f2f2f2; \n",
    "                }}\n",
    "                .prediction-box {{ \n",
    "                    padding: 15px; \n",
    "                    margin: 10px auto; \n",
    "                    border-radius: 5px; \n",
    "                    background-color: #f8f9fa; \n",
    "                    max-width: 800px; \n",
    "                }}\n",
    "                .visualization-grid {{ \n",
    "                    display: grid; \n",
    "                    grid-template-columns: 1fr 1fr; \n",
    "                    gap: 20px; \n",
    "                    margin: 20px auto; \n",
    "                }}\n",
    "                .visualization-item {{ \n",
    "                    border: 1px solid #ddd; \n",
    "                    padding: 15px; \n",
    "                    border-radius: 5px; \n",
    "                }}\n",
    "                .explanation-text {{ \n",
    "                    background-color: #f8f9fa; \n",
    "                    padding: 15px; \n",
    "                    border-left: 4px solid #007bff;\n",
    "                    margin: 10px 0;\n",
    "                    font-size: 14px;\n",
    "                    line-height: 1.5;\n",
    "                    text-align: left;\n",
    "                }}\n",
    "                .centered-image {{ \n",
    "                    display: block; \n",
    "                    margin: auto; \n",
    "                    max-width: 100%; \n",
    "                    height: auto;\n",
    "                }}\n",
    "                h1, h2, h3 {{ \n",
    "                    text-align: center; \n",
    "                }}\n",
    "                .navigation-buttons {{\n",
    "                    text-align: center;\n",
    "                    margin: 20px 0;\n",
    "                    padding: 20px;\n",
    "                    background-color: #e9ecef;\n",
    "                    border-radius: 8px;\n",
    "                }}\n",
    "                .nav-btn {{\n",
    "                    background-color: #007bff;\n",
    "                    color: white;\n",
    "                    border: none;\n",
    "                    padding: 12px 24px;\n",
    "                    margin: 0 10px;\n",
    "                    border-radius: 5px;\n",
    "                    cursor: pointer;\n",
    "                    font-size: 16px;\n",
    "                    font-weight: bold;\n",
    "                    transition: background-color 0.3s;\n",
    "                }}\n",
    "                .nav-btn:hover {{\n",
    "                    background-color: #0056b3;\n",
    "                }}\n",
    "                .nav-btn.active {{\n",
    "                    background-color: #28a745;\n",
    "                }}\n",
    "                .nav-btn:disabled {{\n",
    "                    background-color: #6c757d;\n",
    "                    cursor: not-allowed;\n",
    "                }}\n",
    "                .viz-section {{\n",
    "                    margin-bottom: 30px;\n",
    "                    padding: 20px;\n",
    "                    border: 1px solid #ddd;\n",
    "                    border-radius: 8px;\n",
    "                    background-color: #fafafa;\n",
    "                }}\n",
    "            </style>\n",
    "            <script>\n",
    "                function showSection(sectionId) {{\n",
    "                    // Hide all sections\n",
    "                    var sections = document.querySelectorAll('.section');\n",
    "                    sections.forEach(function(section) {{\n",
    "                        section.classList.remove('active');\n",
    "                    }});\n",
    "                    \n",
    "                    // Show selected section\n",
    "                    document.getElementById(sectionId).classList.add('active');\n",
    "                    \n",
    "                    // Update button states\n",
    "                    var buttons = document.querySelectorAll('.nav-btn');\n",
    "                    buttons.forEach(function(btn) {{\n",
    "                        btn.classList.remove('active');\n",
    "                    }});\n",
    "                    \n",
    "                    // Activate current button\n",
    "                    if (sectionId === 'main-analysis') {{\n",
    "                        document.getElementById('main-btn').classList.add('active');\n",
    "                    }} else {{\n",
    "                        document.getElementById('viz-btn').classList.add('active');\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "                window.onload = function() {{\n",
    "                    showSection('main-analysis');\n",
    "                }}\n",
    "            </script>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"container\">\n",
    "                <h1>LIME Explanation Report - Instance {instance_idx}</h1>\n",
    "                \n",
    "                <div class=\"navigation-buttons\">\n",
    "                    <button id=\"main-btn\" class=\"nav-btn active\" onclick=\"showSection('main-analysis')\">\n",
    "                        Main Analysis\n",
    "                    </button>\n",
    "                    <button id=\"viz-btn\" class=\"nav-btn\" onclick=\"showSection('visualizations')\">\n",
    "                        Global Feature Analysis\n",
    "                    </button>\n",
    "                </div>\n",
    "\n",
    "                <!-- Main Analysis Section -->\n",
    "                <div id=\"main-analysis\" class=\"section active\">\n",
    "                    <div class=\"analysis-subsection\">\n",
    "                        <h2>Prediction Summary</h2>\n",
    "                        <div class=\"prediction-box\">\n",
    "                            <p><strong>Instance ID:</strong> {instance_idx}</p>\n",
    "                            <p><strong>Predicted Class:</strong> {label_encoder.inverse_transform([predicted_class])[0]}</p>\n",
    "                            <p><strong>Prediction Message:</strong> {prediction_message}</p>\n",
    "        \"\"\"\n",
    "        \n",
    "        if attention_plot:\n",
    "            html_content += f\"\"\"\n",
    "                            <img src=\"{attention_plot}\" class=\"centered-image\" style=\"max-width: 800px;\">\n",
    "                            <div class=\"explanation-text\">\n",
    "                                <strong>Attention Visualization:</strong> The top heatmap shows the attention weights across time steps, \n",
    "                                indicating which time points the model focuses on when making predictions. Brighter colors indicate \n",
    "                                higher attention. The bottom graph shows the predicted probabilities for each class, with the green \n",
    "                                bar indicating the model's final prediction.\n",
    "                            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html_content += f\"\"\"\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"analysis-subsection\">\n",
    "                        <h2>Feature Importance Analysis</h2>\n",
    "                        <img src=\"{plot_files['feature']}\" class=\"centered-image\">\n",
    "                        <div class=\"explanation-text\">\n",
    "                            <strong>Feature Importance Graph:</strong> This graph shows the most important features identified by LIME\n",
    "                            and their impact on the prediction. Positive values (bars to the right) show features supporting the prediction,\n",
    "                            while negative values (bars to the left) show features opposing the prediction. Bar length represents the\n",
    "                            feature's importance.\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"analysis-subsection\">\n",
    "                        <h2>Feature Weights Detail</h2>\n",
    "                        <table class=\"feature-table\">\n",
    "                            <tr>\n",
    "                                <th>Feature</th>\n",
    "                                <th>Weight</th>\n",
    "                                <th>Impact</th>\n",
    "                            </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        for _, row in weights_df.iterrows():\n",
    "            impact = \"Positive\" if row['Weight'] > 0 else \"Negative\"\n",
    "            color = \"green\" if row['Weight'] > 0 else \"red\"\n",
    "            html_content += f\"\"\"\n",
    "                            <tr>\n",
    "                                <td>{row['Feature']}</td>\n",
    "                                <td style=\"color: {color}\">{row['Weight']:.4f}</td>\n",
    "                                <td>{impact}</td>\n",
    "                            </tr>\n",
    "            \"\"\"\n",
    "\n",
    "        html_content += f\"\"\"\n",
    "                        </table>\n",
    "                        <div class=\"explanation-text\">\n",
    "                            <strong>Feature Weights Table:</strong> This table shows the numerical weights and impacts of features\n",
    "                            determined by LIME in detail. Positive weights (green) show features supporting the prediction,\n",
    "                            while negative weights (red) show features opposing the prediction.\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"analysis-subsection\">\n",
    "                        <h2>Temporal Feature Importance Analysis</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        if feature_importance_plots[0]:\n",
    "            html_content += f\"\"\"\n",
    "                        <img src=\"{feature_importance_plots[0]}\" class=\"centered-image\">\n",
    "                        <div class=\"explanation-text\">\n",
    "                            <strong>Feature Importance Across Time Steps:</strong> This graph shows which time steps in the \n",
    "                            sequence are most important for this specific vehicle's prediction. Higher importance values indicate \n",
    "                            that the model pays more attention to those specific time points when making decisions. The markers \n",
    "                            show the exact importance values for each time step.\n",
    "                        </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            html_content += \"\"\"\n",
    "                        <p style=\"text-align: center; color: #666;\">Attention-based feature importance analysis not available for this model.</p>\n",
    "            \"\"\"\n",
    "        \n",
    "        html_content += f\"\"\"\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"analysis-subsection\">\n",
    "                        <h2>Time Series Analysis</h2>\n",
    "                        <img src=\"{plot_files['timeseries']}\" class=\"centered-image\">\n",
    "                        <div class=\"explanation-text\">\n",
    "                            <strong>Time Series Graph:</strong> This graph shows the changes in selected features over time.\n",
    "                            Each line represents a different feature and allows us to track how values change.\n",
    "                            This graph helps us understand anomalies, trends, and relationships between features in the time dimension.\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"visualization-grid\">\n",
    "                        <div class=\"visualization-item\">\n",
    "                            <h3>Feature Correlation Analysis</h3>\n",
    "                            <img src=\"{plot_files['correlation']}\" class=\"centered-image\">\n",
    "                            <div class=\"explanation-text\">\n",
    "                                <strong>Correlation Heatmap:</strong> This heatmap shows the strength of relationships between features.\n",
    "                                Dark blue colors indicate strong positive correlation, while dark red colors indicate strong negative correlation.\n",
    "                                This visualization helps us understand which features move together or in opposite directions.\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"visualization-item\">\n",
    "                            <h3>Feature Value Distributions</h3>\n",
    "                            <img src=\"{plot_files['distribution']}\" class=\"centered-image\">\n",
    "                            <div class=\"explanation-text\">\n",
    "                                <strong>Feature Distribution Graph:</strong> This graph shows how the values of each feature are distributed.\n",
    "                                The shape of the distribution provides information about central tendency and spread.\n",
    "                                This information helps us understand whether features follow a normal distribution and identify the presence\n",
    "                                of outliers.\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Visualizations Section -->\n",
    "                <div id=\"visualizations\" class=\"section\">\n",
    "                    <h2>Global Feature Analysis & Model Insights</h2>\n",
    "                    <div class=\"explanation-text\">\n",
    "                        <strong>Global Analysis Overview:</strong> This section contains comprehensive visualizations that analyze \n",
    "                        feature importance patterns across the entire dataset and all prediction classes. These visualizations \n",
    "                        provide insights into the overall model behavior and feature relationships beyond individual predictions.\n",
    "                    </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add visualization images if they exist\n",
    "        for viz in viz_images:\n",
    "            html_content += f\"\"\"\n",
    "                    <div class=\"viz-section\">\n",
    "                        <h3>{viz['title']}</h3>\n",
    "                        <img src=\"{viz['path']}\" class=\"centered-image\">\n",
    "                        <div class=\"explanation-text\">\n",
    "                            {viz['description']}\n",
    "                        </div>\n",
    "                    </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        if not viz_images:\n",
    "            html_content += \"\"\"\n",
    "                    <div class=\"viz-section\">\n",
    "                        <p style=\"text-align: center; color: #666; font-style: italic;\">\n",
    "                            Global visualization files not found in the 'visualizations' directory. \n",
    "                            Please ensure the following files exist in the visualizations folder:\n",
    "                        </p>\n",
    "                        <ul style=\"text-align: left; max-width: 600px; margin: auto;\">\n",
    "                            <li>permutation_feature_importance_bar.png</li>\n",
    "                            <li>permutation_importance_heatmap.png</li>\n",
    "                            <li>class_specific_feature_importance.png</li>\n",
    "                            <li>feature_importance_variance.png</li>\n",
    "                        </ul>\n",
    "                    </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html_content += \"\"\"\n",
    "                </div>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_content)\n",
    "        return report_path\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            self.status.emit(\"Loading data and model...\")\n",
    "            self.progress.emit(10)\n",
    "    \n",
    "            self.model_path = os.path.normpath(self.model_path)\n",
    "            if not os.path.exists(self.model_path):\n",
    "                raise FileNotFoundError(f\"Model file not found at: {self.model_path}\")\n",
    "    \n",
    "            # Create directories\n",
    "            main_dir = \"lime_explanations\"\n",
    "            if not os.path.exists(main_dir):\n",
    "                os.makedirs(main_dir)\n",
    "    \n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            batch_dir = os.path.join(main_dir, f\"batch_{timestamp}\")\n",
    "            os.makedirs(batch_dir)\n",
    "    \n",
    "            # Load and preprocess data\n",
    "            self.status.emit(\"Loading dataset...\")\n",
    "            data = pd.read_csv(self.data_path)\n",
    "            processed_data = self.pipeline.transform(data)\n",
    "            feature_names = processed_data.columns[2:].tolist()\n",
    "            self.status.emit(\"Dataset loaded successfully\")\n",
    "    \n",
    "            # Load model with custom objects\n",
    "            self.status.emit(\"Loading model...\")\n",
    "            custom_objects = {\n",
    "                'weighted_loss': self.weighted_loss,\n",
    "                'custom_cost_metric': self.custom_cost_metric,\n",
    "                'SelfAttention' : SelfAttention\n",
    "            }\n",
    "            try:\n",
    "                model = tf.keras.models.load_model(self.model_path, custom_objects=custom_objects)\n",
    "                self.status.emit(\"Model loaded successfully\")\n",
    "            except Exception as e:\n",
    "                # HDF5 fallback\n",
    "                self.status.emit(f\"Failed to load as .keras: {str(e)}. Trying as HDF5...\")\n",
    "                try:\n",
    "                    model = tf.keras.models.load_model(self.model_path, custom_objects=custom_objects)\n",
    "                    self.status.emit(\"Model loaded successfully as HDF5\")\n",
    "                except Exception as e2:\n",
    "                    self.error.emit(f\"Failed to load model: {str(e2)}\")\n",
    "                    return\n",
    "    \n",
    "            # Load label encoder\n",
    "            try:\n",
    "                label_encoder = joblib.load(self.label_encoder_path)\n",
    "                self.status.emit(\"Label encoder loaded successfully\")\n",
    "            except Exception as e:\n",
    "                self.error.emit(f\"Error loading label encoder: {str(e)}\")\n",
    "                return\n",
    "    \n",
    "            self.status.emit(\"Preprocessing data...\")\n",
    "            self.progress.emit(30)\n",
    "    \n",
    "            # Use the new preprocess_test_data method directly from this class\n",
    "            X_test, vehicle_ids, max_seq_length = self.preprocess_test_data(processed_data)\n",
    "            if X_test is None:\n",
    "                self.error.emit(\"Failed to preprocess data with saved scaler\")\n",
    "                return\n",
    "            \n",
    "            # Make predictions once for all data to avoid TF retracing warning\n",
    "            self.status.emit(\"Making predictions...\")\n",
    "            predictions = model.predict(X_test, batch_size=32, verbose=0)\n",
    "    \n",
    "            # LIME setup and report generation\n",
    "            self.status.emit(\"Setting up LIME explainer...\")\n",
    "            self.progress.emit(50)\n",
    "    \n",
    "            total_instances = min(self.requested_instances, len(vehicle_ids))\n",
    "            self.status.emit(f\"Processing {total_instances} instances (requested: {self.requested_instances})\")\n",
    "    \n",
    "            def create_feature_names(feature_names, timesteps):\n",
    "                return [f\"feature_{feat}_{t}\" for feat in feature_names for t in range(timesteps)]\n",
    "    \n",
    "            formatted_feature_names = create_feature_names(feature_names, max_seq_length)\n",
    "    \n",
    "            lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "                X_test.reshape(X_test.shape[0], -1),\n",
    "                feature_names=formatted_feature_names,\n",
    "                class_names=label_encoder.classes_,\n",
    "                mode='classification',\n",
    "                discretize_continuous=False,\n",
    "            )\n",
    "    \n",
    "            # Create a prediction function that uses fixed batch size\n",
    "            def lime_predict(data):\n",
    "                reshaped_data = data.reshape(data.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "                \n",
    "                # Always use a fixed batch size to avoid retracing\n",
    "                batch_size = 32\n",
    "                \n",
    "                if reshaped_data.shape[0] <= batch_size:\n",
    "                    # Pad to exact batch size\n",
    "                    pad_size = batch_size - reshaped_data.shape[0]\n",
    "                    if pad_size > 0:\n",
    "                        padding = np.zeros((pad_size, X_test.shape[1], X_test.shape[2]))\n",
    "                        padded_data = np.concatenate([reshaped_data, padding], axis=0)\n",
    "                    else:\n",
    "                        padded_data = reshaped_data\n",
    "                    \n",
    "                    # Always predict with exact batch size\n",
    "                    predictions = model.predict(padded_data, batch_size=batch_size, verbose=0)\n",
    "                    return predictions[:reshaped_data.shape[0]]\n",
    "                else:\n",
    "                    # For larger batches, process in chunks of exact batch size\n",
    "                    predictions = []\n",
    "                    for i in range(0, reshaped_data.shape[0], batch_size):\n",
    "                        chunk = reshaped_data[i:i+batch_size]\n",
    "                        if chunk.shape[0] < batch_size:\n",
    "                            # Pad the last chunk to exact batch size\n",
    "                            pad_size = batch_size - chunk.shape[0]\n",
    "                            padding = np.zeros((pad_size, X_test.shape[1], X_test.shape[2]))\n",
    "                            padded_chunk = np.concatenate([chunk, padding], axis=0)\n",
    "                        else:\n",
    "                            padded_chunk = chunk\n",
    "                        \n",
    "                        chunk_pred = model.predict(padded_chunk, batch_size=batch_size, verbose=0)\n",
    "                        predictions.append(chunk_pred[:chunk.shape[0]])\n",
    "                    \n",
    "                    return np.concatenate(predictions, axis=0)\n",
    "            \n",
    "            # Create attention models once if available\n",
    "            attention_models = None\n",
    "            pre_attention_model = None\n",
    "            attention_model = None\n",
    "            try:\n",
    "                attention_models = self.create_attention_model(model)\n",
    "                if attention_models and attention_models[1]:\n",
    "                    pre_attention_model, attention_model = attention_models[0]\n",
    "                    # Compile models to optimize performance\n",
    "                    pre_attention_model.compile(optimizer='adam', loss='mse')\n",
    "                    attention_model.compile(optimizer='adam', loss='mse')\n",
    "                    self.status.emit(\"Attention analysis enabled\")\n",
    "            except:\n",
    "                self.status.emit(\"Attention analysis not available\")\n",
    "    \n",
    "            self.status.emit(\"Generating explanations and reports...\")\n",
    "            \n",
    "            for i, vehicle_id in enumerate(vehicle_ids[:total_instances]):\n",
    "                progress = 50 + (i + 1) * 40 // total_instances\n",
    "                self.progress.emit(progress)\n",
    "                self.status.emit(f\"Processing instance {i+1}/{total_instances}\")\n",
    "    \n",
    "                instance_dir = os.path.join(batch_dir, f\"vehicle_{vehicle_id}\")\n",
    "                os.makedirs(instance_dir, exist_ok=True)\n",
    "    \n",
    "                original_length = len(data[data['vehicle_id'] == vehicle_id])\n",
    "                instance_data = X_test[i].flatten()\n",
    "                explanation = lime_explainer.explain_instance(\n",
    "                    instance_data,\n",
    "                    lime_predict,\n",
    "                    num_features=len(formatted_feature_names)\n",
    "                )\n",
    "    \n",
    "                plot_files, weights_df = self.create_lime_explanation(\n",
    "                    i, explanation, original_length, X_test, predictions,\n",
    "                    instance_dir, vehicle_ids, feature_names\n",
    "                )\n",
    "                \n",
    "                # Generate attention visualization\n",
    "                attention_plot = self.visualize_attention(\n",
    "                    i, X_test, predictions, vehicle_ids, label_encoder, instance_dir, model\n",
    "                )\n",
    "                \n",
    "                # Generate feature importance plots for this specific vehicle\n",
    "                feature_importance_plots = self.create_feature_importance_plots_for_vehicle(\n",
    "                    i, X_test, vehicle_ids, label_encoder, instance_dir, model\n",
    "                )\n",
    "    \n",
    "                report_path = self.create_detailed_report(\n",
    "                    i, explanation, predictions, feature_names,\n",
    "                    label_encoder, plot_files, weights_df, instance_dir,\n",
    "                    attention_plot, feature_importance_plots\n",
    "                )\n",
    "    \n",
    "            self.progress.emit(100)\n",
    "            self.status.emit(\"Reports generated successfully!\")\n",
    "            self.finished.emit(batch_dir)\n",
    "    \n",
    "        except Exception as e:\n",
    "            self.error.emit(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f5cc6b-e77c-440c-b247-aa0266713a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"LIME Explanation Report Generator\")\n",
    "        self.setGeometry(100, 100, 1400, 900)\n",
    "        \n",
    "        self.data_path = None\n",
    "        self.model_path = None\n",
    "        \n",
    "        self.setup_dark_theme()\n",
    "        self.init_ui()\n",
    "\n",
    "    def setup_dark_theme(self):\n",
    "        dark_palette = QPalette()\n",
    "        dark_palette.setColor(QPalette.ColorRole.Window, QColor(53, 53, 53))\n",
    "        dark_palette.setColor(QPalette.ColorRole.WindowText, QColor(255, 255, 255))\n",
    "        dark_palette.setColor(QPalette.ColorRole.Base, QColor(35, 35, 35))\n",
    "        dark_palette.setColor(QPalette.ColorRole.AlternateBase, QColor(53, 53, 53))\n",
    "        dark_palette.setColor(QPalette.ColorRole.ToolTipBase, QColor(255, 255, 255))\n",
    "        dark_palette.setColor(QPalette.ColorRole.ToolTipText, QColor(255, 255, 255))\n",
    "        dark_palette.setColor(QPalette.ColorRole.Text, QColor(255, 255, 255))\n",
    "        dark_palette.setColor(QPalette.ColorRole.Button, QColor(53, 53, 53))\n",
    "        dark_palette.setColor(QPalette.ColorRole.ButtonText, QColor(255, 255, 255))\n",
    "        dark_palette.setColor(QPalette.ColorRole.BrightText, QColor(255, 0, 0))\n",
    "        dark_palette.setColor(QPalette.ColorRole.Link, QColor(42, 130, 218))\n",
    "        dark_palette.setColor(QPalette.ColorRole.Highlight, QColor(42, 130, 218))\n",
    "        dark_palette.setColor(QPalette.ColorRole.HighlightedText, QColor(255, 255, 255))\n",
    "        self.setPalette(dark_palette)\n",
    "\n",
    "    def init_ui(self):\n",
    "        main_widget = QWidget()\n",
    "        main_layout = QVBoxLayout(main_widget)\n",
    "        \n",
    "        # Header section\n",
    "        header_widget = QWidget()\n",
    "        header_layout = QHBoxLayout(header_widget)\n",
    "        \n",
    "        # Title\n",
    "        title_label = QLabel(\"LIME Explanation Report Generator\")\n",
    "        title_label.setStyleSheet(\"\"\"\n",
    "            font-size: 28px;\n",
    "            font-weight: bold;\n",
    "            color: #4CAF50;\n",
    "            padding: 10px;\n",
    "        \"\"\")\n",
    "        title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        header_layout.addWidget(title_label)\n",
    "        \n",
    "        main_layout.addWidget(header_widget)\n",
    "\n",
    "        # Create splitter for tables and controls\n",
    "        splitter = QSplitter(Qt.Orientation.Horizontal)\n",
    "        \n",
    "        # Left side - Table views with tabs\n",
    "        self.tab_widget = QTabWidget()\n",
    "        self.tab_widget.setStyleSheet(\"\"\"\n",
    "            QTabWidget::pane {\n",
    "                border: 1px solid #444;\n",
    "                background: #2d2d2d;\n",
    "            }\n",
    "            QTabBar::tab {\n",
    "                background: #353535;\n",
    "                color: #fff;\n",
    "                padding: 8px 12px;\n",
    "                border: 1px solid #444;\n",
    "                border-bottom: none;\n",
    "            }\n",
    "            QTabBar::tab:selected {\n",
    "                background: #4CAF50;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        # Original data tab\n",
    "        original_tab = QWidget()\n",
    "        original_layout = QVBoxLayout(original_tab)\n",
    "        self.original_table_view = QTableView()\n",
    "        self.setup_table_view(self.original_table_view)\n",
    "        self.original_table_model = DataTableModel()\n",
    "        self.original_table_view.setModel(self.original_table_model)\n",
    "        original_layout.addWidget(self.original_table_view)\n",
    "        self.tab_widget.addTab(original_tab, \"Original Data\")\n",
    "        \n",
    "        # Processed data tab\n",
    "        processed_tab = QWidget()\n",
    "        processed_layout = QVBoxLayout(processed_tab)\n",
    "        self.processed_table_view = QTableView()\n",
    "        self.setup_table_view(self.processed_table_view)\n",
    "        self.processed_table_model = DataTableModel()\n",
    "        self.processed_table_view.setModel(self.processed_table_model)\n",
    "        processed_layout.addWidget(self.processed_table_view)\n",
    "        self.tab_widget.addTab(processed_tab, \"Processed Data\")\n",
    "        \n",
    "        # Add statistics labels with improved styling\n",
    "        self.original_stats_label = QLabel()\n",
    "        self.processed_stats_label = QLabel()\n",
    "        self.setup_stats_label(self.original_stats_label)\n",
    "        self.setup_stats_label(self.processed_stats_label)\n",
    "        original_layout.addWidget(self.original_stats_label)\n",
    "        processed_layout.addWidget(self.processed_stats_label)\n",
    "        \n",
    "        splitter.addWidget(self.tab_widget)\n",
    "        \n",
    "        # Right side - Controls\n",
    "        controls_widget = QWidget()\n",
    "        controls_layout = QVBoxLayout(controls_widget)\n",
    "        controls_layout.setSpacing(15)\n",
    "        \n",
    "        # File selection section\n",
    "        file_section = QFrame()\n",
    "        file_section.setFrameStyle(QFrame.Shape.StyledPanel | QFrame.Shadow.Raised)\n",
    "        file_layout = QVBoxLayout(file_section)\n",
    "        \n",
    "        # Dataset selection\n",
    "        data_widget = QWidget()\n",
    "        data_layout = QHBoxLayout(data_widget)\n",
    "        self.data_label = QLabel(\"No dataset selected\")\n",
    "        self.data_label.setStyleSheet(\"color: #aaa;\")\n",
    "        select_data_btn = StyledButton(\"Select Dataset\")\n",
    "        select_data_btn.clicked.connect(self.select_data)\n",
    "        data_layout.addWidget(self.data_label)\n",
    "        data_layout.addWidget(select_data_btn)\n",
    "        file_layout.addWidget(data_widget)\n",
    "\n",
    "        # Model selection\n",
    "        model_widget = QWidget()\n",
    "        model_layout = QHBoxLayout(model_widget)\n",
    "        self.model_label = QLabel(\"No model selected\")\n",
    "        self.model_label.setStyleSheet(\"color: #aaa;\")\n",
    "        select_model_btn = StyledButton(\"Select Model\")\n",
    "        select_model_btn.clicked.connect(self.select_model)\n",
    "        model_layout.addWidget(self.model_label)\n",
    "        model_layout.addWidget(select_model_btn)\n",
    "        file_layout.addWidget(model_widget)\n",
    "        \n",
    "        controls_layout.addWidget(file_section)\n",
    "        \n",
    "        # Options section\n",
    "        options_section = QFrame()\n",
    "        options_section.setFrameStyle(QFrame.Shape.StyledPanel | QFrame.Shadow.Raised)\n",
    "        options_layout = QVBoxLayout(options_section)\n",
    "        \n",
    "        # Add instance count selector\n",
    "        instance_widget = QWidget()\n",
    "        instance_layout = QHBoxLayout(instance_widget)\n",
    "        instance_label = QLabel(\"Number of instances to analyze:\")\n",
    "        self.instance_combo = QComboBox()\n",
    "        self.instance_combo.addItems(['1', '3', '5', '10'])\n",
    "        self.instance_combo.setCurrentText('5')\n",
    "        instance_layout.addWidget(instance_label)\n",
    "        instance_layout.addWidget(self.instance_combo)\n",
    "        options_layout.addWidget(instance_widget)\n",
    "        \n",
    "        controls_layout.addWidget(options_section)\n",
    "        \n",
    "        # Generate button\n",
    "        self.generate_btn = StyledButton(\"Generate LIME Report\")\n",
    "        self.generate_btn.setEnabled(False)\n",
    "        self.generate_btn.clicked.connect(self.generate_report)\n",
    "        controls_layout.addWidget(self.generate_btn)\n",
    "        \n",
    "        # Progress bar\n",
    "        self.progress_bar = StyledProgressBar()\n",
    "        self.progress_bar.setVisible(False)\n",
    "        controls_layout.addWidget(self.progress_bar)\n",
    "        \n",
    "        # Status log\n",
    "        self.log_output = QTextEdit()\n",
    "        self.log_output.setReadOnly(True)\n",
    "        self.log_output.setStyleSheet(\"\"\"\n",
    "            QTextEdit {\n",
    "                background-color: #2d2d2d;\n",
    "                color: #fff;\n",
    "                border: 1px solid #444;\n",
    "                border-radius: 4px;\n",
    "                padding: 5px;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.log_output.setMinimumHeight(300)\n",
    "        controls_layout.addWidget(self.log_output)\n",
    "        \n",
    "        splitter.addWidget(controls_widget)\n",
    "        \n",
    "        # Set splitter sizes\n",
    "        splitter.setSizes([int(self.width() * 0.6), int(self.width() * 0.4)])\n",
    "        \n",
    "        # Add splitter to main layout\n",
    "        main_layout.addWidget(splitter)\n",
    "        \n",
    "        self.setCentralWidget(main_widget)\n",
    "\n",
    "    def setup_table_view(self, table_view):\n",
    "        table_view.setStyleSheet(\"\"\"\n",
    "            QTableView {\n",
    "                background-color: #2d2d2d;\n",
    "                alternate-background-color: #353535;\n",
    "                color: #fff;\n",
    "                gridline-color: #444;\n",
    "                selection-background-color: #4CAF50;\n",
    "                selection-color: #fff;\n",
    "            }\n",
    "            QHeaderView::section {\n",
    "                background-color: #404040;\n",
    "                color: #fff;\n",
    "                padding: 5px;\n",
    "                border: 1px solid #444;\n",
    "            }\n",
    "        \"\"\")\n",
    "        table_view.setAlternatingRowColors(True)\n",
    "        table_view.horizontalHeader().setStretchLastSection(True)\n",
    "        table_view.verticalHeader().setDefaultSectionSize(25)\n",
    "        table_view.setShowGrid(True)\n",
    "\n",
    "    def setup_stats_label(self, label):\n",
    "        label.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                background-color: #2d2d2d;\n",
    "                color: #fff;\n",
    "                padding: 10px;\n",
    "                border: 1px solid #444;\n",
    "                border-radius: 4px;\n",
    "                margin-top: 5px;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "    def update_stats_labels(self, original_df, processed_df):\n",
    "        # Update statistics for original data\n",
    "        original_stats = (\n",
    "            f\"Original Data Statistics:\\n\"\n",
    "            f\"Rows: {len(original_df)}\\n\"\n",
    "            f\"Columns: {len(original_df.columns)}\\n\"\n",
    "            f\"Missing Values: {original_df.isnull().sum().sum()}\"\n",
    "        )\n",
    "        self.original_stats_label.setText(original_stats)\n",
    "        \n",
    "        # Update statistics for processed data\n",
    "        processed_stats = (\n",
    "            f\"Processed Data Statistics:\\n\"\n",
    "            f\"Rows: {len(processed_df)}\\n\"\n",
    "            f\"Columns: {len(processed_df.columns)}\\n\"\n",
    "            f\"Missing Values: {processed_df.isnull().sum().sum()}\"\n",
    "        )\n",
    "        self.processed_stats_label.setText(processed_stats)\n",
    "\n",
    "    def select_data(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Select Dataset\", \"\", \"CSV Files (*.csv)\"\n",
    "        )\n",
    "        if file_path:\n",
    "            self.data_path = file_path\n",
    "            self.data_label.setText(f\"Dataset: {os.path.basename(file_path)}\")\n",
    "            \n",
    "            try:\n",
    "                # Load original data\n",
    "                original_df = pd.read_csv(file_path)\n",
    "                self.original_table_model.load_data(original_df)\n",
    "                \n",
    "                # Apply preprocessing pipeline\n",
    "                pipeline = DataPreprocessingPipeline()\n",
    "                processed_df = pipeline.transform(original_df)\n",
    "                self.processed_table_model.load_data(processed_df)\n",
    "                \n",
    "                # Update statistics\n",
    "                self.update_stats_labels(original_df, processed_df)\n",
    "                \n",
    "                self.log_output.append(f\"Loaded and preprocessed dataset: {os.path.basename(file_path)}\")\n",
    "                self.check_generate_button()\n",
    "                \n",
    "                # Switch to processed data tab\n",
    "                self.tab_widget.setCurrentIndex(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.log_output.append(f\"Error loading dataset: {str(e)}\")\n",
    "\n",
    "    def select_model(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Select Model\", \"\", \"Keras Model (*.keras);;All Files (*.*)\"\n",
    "        )\n",
    "        if file_path:\n",
    "            self.model_path = os.path.normpath(file_path.replace('/', os.sep))\n",
    "            self.model_label.setText(f\"Model: {os.path.basename(file_path)}\")\n",
    "            \n",
    "            if os.path.exists(self.model_path):\n",
    "                self.log_output.append(f\"Selected model: {os.path.basename(file_path)}\")\n",
    "            else:\n",
    "                self.log_output.append(f\"Error: Model file not found\")\n",
    "            \n",
    "            self.check_generate_button()\n",
    "\n",
    "    def check_generate_button(self):\n",
    "        self.generate_btn.setEnabled(self.data_path is not None and self.model_path is not None)\n",
    "\n",
    "    def generate_report(self):\n",
    "        if not self.data_path or not self.model_path:\n",
    "            return\n",
    "            \n",
    "        self.progress_bar.setVisible(True)\n",
    "        self.progress_bar.setValue(0)\n",
    "        self.generate_btn.setEnabled(False)\n",
    "        self.log_output.append(\"Starting report generation...\")\n",
    "        \n",
    "        # Get number of instances from combo box\n",
    "        num_instances = int(self.instance_combo.currentText())\n",
    "        \n",
    "        # Create and start the thread with number of instances\n",
    "        self.thread = LIMEReportThread(self.data_path, self.model_path, num_instances)\n",
    "        self.thread.progress.connect(self.update_progress)\n",
    "        self.thread.status.connect(self.update_status)\n",
    "        self.thread.finished.connect(self.report_finished)\n",
    "        self.thread.error.connect(self.handle_error)\n",
    "        self.thread.start()\n",
    "\n",
    "    def handle_error(self, error_message):\n",
    "        self.progress_bar.setVisible(False)\n",
    "        self.generate_btn.setEnabled(True)\n",
    "        self.log_output.append(f\"Error: {error_message}\")\n",
    "        \n",
    "        # Show error in more visible way\n",
    "        error_msg = QLabel(error_message)\n",
    "        error_msg.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                color: #ff4444;\n",
    "                padding: 10px;\n",
    "                background: #2d2d2d;\n",
    "                border: 1px solid #ff4444;\n",
    "                border-radius: 4px;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.log_output.append(\"\\n\" + error_message)\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_bar.setValue(value)\n",
    "\n",
    "    def update_status(self, message):\n",
    "        self.log_output.append(message)\n",
    "\n",
    "    def report_finished(self, results_dir):\n",
    "        self.progress_bar.setVisible(False)\n",
    "        self.generate_btn.setEnabled(True)\n",
    "        self.log_output.append(f\"Reports generated successfully in: {results_dir}\")\n",
    "        # Open the batch directory containing all vehicle reports\n",
    "        os.startfile(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa466bd-6879-48b0-8fa2-ee8e8d1f94d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:5 out of the last 162 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002451757C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:5 out of the last 162 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000245175AA050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "app = QApplication(sys.argv)\n",
    "window = MainWindow()\n",
    "window.show()\n",
    "sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b981d61-4653-4ea2-be44-9c40e97cf7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
